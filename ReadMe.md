# Обучение модели детектирования Yolov5

Выполнено в репозитории https://github.com/ultralytics/yolov5.

## Требования к компьютеру и ПО
Репозиторий протестирован на Windows 10.
<br>Для поддержки GPU а компьютере должна быть установлена Cuda Toolkit 10.х или 11.х (протестировано на версиях 10.1, 11.4) и CudNN. Pytorch устанавливает Cuda Toolkit отдельно, при его установке можно выбрать версию cuda. Поэтому версия Cuda Toolkit, установленная на компьютере, не имеет значения.
<br>Для теста использовались видеокарты Nvidia GeForce GTX 1060, GTX 1660 Ti.

## Установка
1. Установите на компьютер менеджер виртуальных сред Anaconda.
2. Откройте командную строку Anaconda, создайте новую среду и установите необходимые библиотеки:
    - conda create -n yolov5 python=3.8
    - conda activate yolov5
    <br>Установка pytorch с Cuda Toolkit 11.3:
    - pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html
    - Перейдите в каталог, в который хотите склонировать репозиторий Yolov5.
    - Выполните команду: git clone https://github.com/ultralytics/yolov5
    - Перейдите в скачанный репозиторий: cd yolov5
    - Установите пакеты: pip install -r requirements.txt

## Подготовка данных
Перейдите в скачанный [репозиторий](https://github.com/ultralytics/yolov5).
1. Для однообразия необходимо положить изображения в папку images. В этой папке для удобства создайте папки train, val, test и положите в них соотвествующие изображения для обучения, валидации и тестирования. 

2. Разметьте в своем датасете классы номерами. Теперь необходимо создать файлы *.txt с номерами классов и координатами истинных объектов классов. Каждый файл соотвествует одному изображению с таким же именем, как и имя изображения в папке images, но расширением *.txt. Данные текстовые файлы необходимо положить в соотвествующие папки: labels/train, labels/val, labels/test.
<br>Содержимое каждого текстового файла (значения через пробел):
<br>nclass xcenter ycenter w h
<br>где:
<br>nclass - номер класса (нумерация начинается с нуля),
<br>xcenter - координата по горизонтали центра объекта,
<br>ycenter - координата по вертикали центра объекта,
<br>w - ширина объекта,
<br>h - высота объекта.
<br>Значения координат, ограничивающих прямоугольник должны быть нормализованы на размер изображения, то есть находятся в пределах от 0 до 1.
<br>Пример содержимого файла 0.txt (соответствующего изображению 0.png) для трех объектов:
<br>0 0.2109375 0.3765625 0.05 0.48125
<br>0 0.21328125 0.05859375 0.0515625 0.1171875
<br>0 0.21328125 0.8 0.0515625 0.4

3. В папке data создайте файлы списков изображений: train.txt, val.txt, test.txt.
<br>В каждом файле содержится список путей к изображениям для обучения, валидации и тестирования. Каждый путь записывается с новой строки.
<br>Пример содержимого файла train.txt:
<br>C:/yolov5/images/train/0.png
<br>C:/yolov5/images/train/1.png
<br>...
<br>C:/yolov5/images/train/n.png

3. По образцу файла data/coco.yaml создайте свой файл и заполните его путями к спискам изображений, созданных шагом ранее, количеством и списком классов. В репозитории содержится пример такого файла - data_conf.yaml.

4. Выберите модель yolov5, которую хотите дообучать. Перечень моделей можно найти в исходном [репозитории](https://github.com/ultralytics/yolov5). Скачайте выбранную предобученную модель. Скачанную модель положите в папку models.

5. В папке models выберите конфигурационный файл, соответствующий выбранной модели и отредактируйте в нем количество классов, например yolov5s.yaml.

## Обучение

Инструкции и команды по обучению находятся в ноутбуке yolov5.ipynb.

Команды можно выполнять либо напрямую из ноутбука (со знаком !), либо из командной строки созданной среды Anaconda.